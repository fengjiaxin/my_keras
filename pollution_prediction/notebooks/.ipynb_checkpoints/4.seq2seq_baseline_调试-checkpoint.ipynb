{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### baseline"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "最简单的seq2seq_baseline\n",
    "其中预测当天小时的污染程度，但是有一些自变量是已知的\n",
    "并且前几天的污染程度也可以当作一些特征，问题的关键是如何构建这些特征进行训练"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from datetime import date, timedelta,datetime\n",
    "import gc\n",
    "import tensorflow as tf\n",
    "from sklearn import metrics\n",
    "from tensorflow.keras import Model\n",
    "from tensorflow.keras.layers import Input,Lambda,concatenate,GRU,Dense,Conv1D,Reshape,Embedding\n",
    "from tensorflow.keras.utils import Sequence\n",
    "import math\n",
    "import logging\n",
    "logging.basicConfig(level=logging.INFO)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_df = pd.read_csv('../data/pollution.csv',parse_dates = ['date'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>pollution</th>\n",
       "      <th>dew</th>\n",
       "      <th>temp</th>\n",
       "      <th>press</th>\n",
       "      <th>wnd_dir</th>\n",
       "      <th>wnd_spd</th>\n",
       "      <th>snow</th>\n",
       "      <th>rain</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2010-01-02 00:00:00</td>\n",
       "      <td>129.0</td>\n",
       "      <td>-16</td>\n",
       "      <td>-4.0</td>\n",
       "      <td>1020.0</td>\n",
       "      <td>SE</td>\n",
       "      <td>1.79</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2010-01-02 01:00:00</td>\n",
       "      <td>148.0</td>\n",
       "      <td>-15</td>\n",
       "      <td>-4.0</td>\n",
       "      <td>1020.0</td>\n",
       "      <td>SE</td>\n",
       "      <td>2.68</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2010-01-02 02:00:00</td>\n",
       "      <td>159.0</td>\n",
       "      <td>-11</td>\n",
       "      <td>-5.0</td>\n",
       "      <td>1021.0</td>\n",
       "      <td>SE</td>\n",
       "      <td>3.57</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2010-01-02 03:00:00</td>\n",
       "      <td>181.0</td>\n",
       "      <td>-7</td>\n",
       "      <td>-5.0</td>\n",
       "      <td>1022.0</td>\n",
       "      <td>SE</td>\n",
       "      <td>5.36</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2010-01-02 04:00:00</td>\n",
       "      <td>138.0</td>\n",
       "      <td>-7</td>\n",
       "      <td>-5.0</td>\n",
       "      <td>1022.0</td>\n",
       "      <td>SE</td>\n",
       "      <td>6.25</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 date  pollution  dew  temp   press wnd_dir  wnd_spd  snow  \\\n",
       "0 2010-01-02 00:00:00      129.0  -16  -4.0  1020.0      SE     1.79     0   \n",
       "1 2010-01-02 01:00:00      148.0  -15  -4.0  1020.0      SE     2.68     0   \n",
       "2 2010-01-02 02:00:00      159.0  -11  -5.0  1021.0      SE     3.57     0   \n",
       "3 2010-01-02 03:00:00      181.0   -7  -5.0  1022.0      SE     5.36     1   \n",
       "4 2010-01-02 04:00:00      138.0   -7  -5.0  1022.0      SE     6.25     2   \n",
       "\n",
       "   rain  \n",
       "0     0  \n",
       "1     0  \n",
       "2     0  \n",
       "3     0  \n",
       "4     0  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "raw_df.head()"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "可以看出数据的日期是 从 2010-01-02 00:00:00  到  2014-12-31 23:00:00\n",
    "其中说明一下各列代表的含义：\n",
    "pollution:PM2.5浓度\n",
    "dew:露点\n",
    "temp:温度\n",
    "press:压力\n",
    "wnd_dir:综合风向\n",
    "wnd_spd:累计风速\n",
    "snow:累计下了几个小时的雪\n",
    "rain:累计下了几个小时的雨"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "目的：生成两个df\n",
    "pollution_df:只有一行，多列，其中列是日期，value是污染pollution\n",
    "dew_df:只有一行，多列，其中列是日期，value是露点dew"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 生成pollution_df\n",
    "raw_df['variable'] = 'pollution'\n",
    "pollution_df = raw_df[['date','pollution','variable']].set_index(['variable','date'])[['pollution']].unstack(level=-1)\n",
    "pollution_df.columns = pollution_df.columns.get_level_values(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>date</th>\n",
       "      <th>2010-01-02 00:00:00</th>\n",
       "      <th>2010-01-02 01:00:00</th>\n",
       "      <th>2010-01-02 02:00:00</th>\n",
       "      <th>2010-01-02 03:00:00</th>\n",
       "      <th>2010-01-02 04:00:00</th>\n",
       "      <th>2010-01-02 05:00:00</th>\n",
       "      <th>2010-01-02 06:00:00</th>\n",
       "      <th>2010-01-02 07:00:00</th>\n",
       "      <th>2010-01-02 08:00:00</th>\n",
       "      <th>2010-01-02 09:00:00</th>\n",
       "      <th>...</th>\n",
       "      <th>2014-12-31 14:00:00</th>\n",
       "      <th>2014-12-31 15:00:00</th>\n",
       "      <th>2014-12-31 16:00:00</th>\n",
       "      <th>2014-12-31 17:00:00</th>\n",
       "      <th>2014-12-31 18:00:00</th>\n",
       "      <th>2014-12-31 19:00:00</th>\n",
       "      <th>2014-12-31 20:00:00</th>\n",
       "      <th>2014-12-31 21:00:00</th>\n",
       "      <th>2014-12-31 22:00:00</th>\n",
       "      <th>2014-12-31 23:00:00</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>variable</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>pollution</th>\n",
       "      <td>129.0</td>\n",
       "      <td>148.0</td>\n",
       "      <td>159.0</td>\n",
       "      <td>181.0</td>\n",
       "      <td>138.0</td>\n",
       "      <td>109.0</td>\n",
       "      <td>105.0</td>\n",
       "      <td>124.0</td>\n",
       "      <td>120.0</td>\n",
       "      <td>132.0</td>\n",
       "      <td>...</td>\n",
       "      <td>9.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>12.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1 rows × 43800 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "date       2010-01-02 00:00:00  2010-01-02 01:00:00  2010-01-02 02:00:00  \\\n",
       "variable                                                                   \n",
       "pollution                129.0                148.0                159.0   \n",
       "\n",
       "date       2010-01-02 03:00:00  2010-01-02 04:00:00  2010-01-02 05:00:00  \\\n",
       "variable                                                                   \n",
       "pollution                181.0                138.0                109.0   \n",
       "\n",
       "date       2010-01-02 06:00:00  2010-01-02 07:00:00  2010-01-02 08:00:00  \\\n",
       "variable                                                                   \n",
       "pollution                105.0                124.0                120.0   \n",
       "\n",
       "date       2010-01-02 09:00:00  ...  2014-12-31 14:00:00  2014-12-31 15:00:00  \\\n",
       "variable                        ...                                             \n",
       "pollution                132.0  ...                  9.0                 11.0   \n",
       "\n",
       "date       2014-12-31 16:00:00  2014-12-31 17:00:00  2014-12-31 18:00:00  \\\n",
       "variable                                                                   \n",
       "pollution                  8.0                  9.0                 10.0   \n",
       "\n",
       "date       2014-12-31 19:00:00  2014-12-31 20:00:00  2014-12-31 21:00:00  \\\n",
       "variable                                                                   \n",
       "pollution                  8.0                 10.0                 10.0   \n",
       "\n",
       "date       2014-12-31 22:00:00  2014-12-31 23:00:00  \n",
       "variable                                             \n",
       "pollution                  8.0                 12.0  \n",
       "\n",
       "[1 rows x 43800 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pollution_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 生成dew_df\n",
    "raw_df['variable'] = 'dew'\n",
    "dew_df = raw_df[['date','pollution','variable']].set_index(['variable','date'])[['pollution']].unstack(level=-1)\n",
    "dew_df.columns = dew_df.columns.get_level_values(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>date</th>\n",
       "      <th>2010-01-02 00:00:00</th>\n",
       "      <th>2010-01-02 01:00:00</th>\n",
       "      <th>2010-01-02 02:00:00</th>\n",
       "      <th>2010-01-02 03:00:00</th>\n",
       "      <th>2010-01-02 04:00:00</th>\n",
       "      <th>2010-01-02 05:00:00</th>\n",
       "      <th>2010-01-02 06:00:00</th>\n",
       "      <th>2010-01-02 07:00:00</th>\n",
       "      <th>2010-01-02 08:00:00</th>\n",
       "      <th>2010-01-02 09:00:00</th>\n",
       "      <th>...</th>\n",
       "      <th>2014-12-31 14:00:00</th>\n",
       "      <th>2014-12-31 15:00:00</th>\n",
       "      <th>2014-12-31 16:00:00</th>\n",
       "      <th>2014-12-31 17:00:00</th>\n",
       "      <th>2014-12-31 18:00:00</th>\n",
       "      <th>2014-12-31 19:00:00</th>\n",
       "      <th>2014-12-31 20:00:00</th>\n",
       "      <th>2014-12-31 21:00:00</th>\n",
       "      <th>2014-12-31 22:00:00</th>\n",
       "      <th>2014-12-31 23:00:00</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>variable</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>dew</th>\n",
       "      <td>129.0</td>\n",
       "      <td>148.0</td>\n",
       "      <td>159.0</td>\n",
       "      <td>181.0</td>\n",
       "      <td>138.0</td>\n",
       "      <td>109.0</td>\n",
       "      <td>105.0</td>\n",
       "      <td>124.0</td>\n",
       "      <td>120.0</td>\n",
       "      <td>132.0</td>\n",
       "      <td>...</td>\n",
       "      <td>9.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>12.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1 rows × 43800 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "date      2010-01-02 00:00:00  2010-01-02 01:00:00  2010-01-02 02:00:00  \\\n",
       "variable                                                                  \n",
       "dew                     129.0                148.0                159.0   \n",
       "\n",
       "date      2010-01-02 03:00:00  2010-01-02 04:00:00  2010-01-02 05:00:00  \\\n",
       "variable                                                                  \n",
       "dew                     181.0                138.0                109.0   \n",
       "\n",
       "date      2010-01-02 06:00:00  2010-01-02 07:00:00  2010-01-02 08:00:00  \\\n",
       "variable                                                                  \n",
       "dew                     105.0                124.0                120.0   \n",
       "\n",
       "date      2010-01-02 09:00:00  ...  2014-12-31 14:00:00  2014-12-31 15:00:00  \\\n",
       "variable                       ...                                             \n",
       "dew                     132.0  ...                  9.0                 11.0   \n",
       "\n",
       "date      2014-12-31 16:00:00  2014-12-31 17:00:00  2014-12-31 18:00:00  \\\n",
       "variable                                                                  \n",
       "dew                       8.0                  9.0                 10.0   \n",
       "\n",
       "date      2014-12-31 19:00:00  2014-12-31 20:00:00  2014-12-31 21:00:00  \\\n",
       "variable                                                                  \n",
       "dew                       8.0                 10.0                 10.0   \n",
       "\n",
       "date      2014-12-31 22:00:00  2014-12-31 23:00:00  \n",
       "variable                                            \n",
       "dew                       8.0                 12.0  \n",
       "\n",
       "[1 rows x 43800 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dew_df"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "整理思路：\n",
    "1.首先需要预测的是pollution\n",
    "2.需要预测的是后7天的每个小时的污染程度\n",
    "3.先假定根据前一个月的数据来预测后7天的数据\n",
    "\n",
    "\n",
    "有个理解错误的地方\n",
    "timesetps时间步的含义是t时刻的value 与 t-timesteps ~ t-1 的value相关\n",
    "在decoder的过程中，需要不断更新seq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_xy_span(df, pred_start, timesteps,periods,is_train=True):\n",
    "    '''\n",
    "        function:首先说一下需求，然后才能更好的了解函数的功能\n",
    "        需求:该时刻的pollution可能和60天前的pollution相关，需要将60天前的pollution提取出来，作为该时刻的特征\n",
    "        timesteps代笔时间步，我们需要构建timesteps个时刻的的特征\n",
    "        periods代表需要预测的时间段长度        \n",
    "    '''\n",
    "    X = df[pd.date_range(pred_start-timedelta(hours=timesteps), pred_start-timedelta(hours=1),freq='H')].values\n",
    "    if is_train: y = df[pd.date_range(pred_start, periods = periods,freq='H')].values\n",
    "    else: y = None\n",
    "    return X, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_dataset_base(df, dew_df, timesteps,periods, pred_start, is_train):\n",
    "    '''\n",
    "        function:创建数据集合\n",
    "        df:污染数据\n",
    "        dew_df:露点数据\n",
    "        timesteps:时间步\n",
    "        pred_start:开始预测的时间点\n",
    "        periods:后续预测的时间段\n",
    "        is_train:是否是训练数据\n",
    "    '''\n",
    "\n",
    "    # 首先可以获取最基本的pollution数据\n",
    "    # X:[1,timesteps] y:[1,periods]\n",
    "    X, y = create_xy_span(df, pred_start, timesteps,periods,is_train)\n",
    "    \n",
    "    # dew 包含训练和测试的露点数据\n",
    "    # dew:[1,timesteps + periods]\n",
    "    dew = dew_df[pd.date_range(pred_start-timedelta(hours=timesteps), periods=timesteps+periods,freq='H')].values\n",
    "    \n",
    "    \n",
    "    # 获取hour特征 hour:[1,timesteps + periods]\n",
    "    hour = np.tile([d.hour for d in pd.date_range(pred_start-timedelta(hours=timesteps), periods=timesteps+periods,freq='H')],\n",
    "                          (X.shape[0],1))\n",
    "    \n",
    "    # 获取week特征 week:[1,timesteps + periods]\n",
    "    weekday = np.tile([d.weekday() for d in pd.date_range(pred_start-timedelta(hours=timesteps), periods=timesteps+periods,freq='H')],\n",
    "                          (X.shape[0],1))\n",
    "    # 获取day特征 day:[1,timesteps + periods]\n",
    "    dayOfMonth = np.tile([d.day-1 for d in pd.date_range(pred_start-timedelta(hours=timesteps), periods=timesteps+periods,freq='H')],\n",
    "                          (X.shape[0],1))\n",
    "    \n",
    "    # 将3个月前,91天的pollution作为特征 quater:[1,timesteps + periods]\n",
    "    #qauaterAgo, _ = create_xy_span(df, pred_start-timedelta(days=91), timesteps+16, False)\n",
    "    \n",
    "    # reshape 数据\n",
    "    X= X.reshape(-1,timesteps,1)\n",
    "    dew = dew.reshape(-1, timesteps + periods, 1)\n",
    "    hour = hour.reshape(-1, timesteps + periods, 1)\n",
    "    weekday = weekday.reshape(-1, timesteps + periods, 1)\n",
    "    dayOfMonth = dayOfMonth.reshape(-1, timesteps + periods, 1)\n",
    "    #qauaterAgo = qauaterAgo.reshape(-1, timesteps + periods, 1)\n",
    "\n",
    "    #return ([X,dew,weekAgo,hour,weekday,dayOfMonth,qauaterAgo],y)\n",
    "    return ([X,dew,hour,weekday,dayOfMonth],y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create validation and test data\n",
    "def create_dataset(df, dew_df, timesteps, periods,first_pred_start, is_train=True):\n",
    "    return create_dataset_base(df, dew_df, timesteps,periods, first_pred_start, is_train)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "接下来创建训练数据生成器，每次批量生成数据\n",
    "在这个例子中，batch_size = 1\n",
    "n_range 代表生成多少个样本"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DataGenerator(Sequence):\n",
    "    '''\n",
    "        generate data for keras\n",
    "        df,dew_df都是一行数据\n",
    "        这个比较特殊，只能先设定batch_size = 1\n",
    "    '''\n",
    "    def __init__(self,df, dew_df, timesteps, first_pred_start,n_range, periods, batch_size,shuffle=True):\n",
    "        '''\n",
    "            df:pollution数据，列为时间\n",
    "            dew_df:露点数据，列为时间\n",
    "            timesteps:时间步\n",
    "            first_pred_start:需要预测pollution的开始日期\n",
    "            n_range:代表可以划分为多少个时间段数据\n",
    "            假设df 列 如下：\n",
    "            1.1,1.2,1.3,1.4,1.5,1.6,1.7,1.8,1.9,1.10\n",
    "            timesteps = 3\n",
    "            periods = 2\n",
    "            first_pred_start = 1.9\n",
    "            那么可以确定划分为6份数据\n",
    "            batch_size:批量数据\n",
    "        '''\n",
    "        self.df = df\n",
    "        self.dew_df = dew_df\n",
    "        self.timesteps = timesteps\n",
    "        self.first_pred_start = first_pred_start\n",
    "        self.n_range = n_range\n",
    "        self.periods = periods\n",
    "        if batch_size != 1:\n",
    "            self.batch_size = 1\n",
    "        else:\n",
    "            self.batch_size = batch_size\n",
    "        self.shuffle = shuffle\n",
    "        # 日期的索引\n",
    "        self.date_indexs = range(n_range)\n",
    "        \n",
    "        \n",
    "    def __len__(self):\n",
    "        '''\n",
    "            计算每一个epoch的迭代个数\n",
    "        '''\n",
    "        return math.ceil(self.n_range/self.batch_size)\n",
    "    \n",
    "    \n",
    "    def on_epoch_end(self):\n",
    "        '''\n",
    "            每次epoch结束后,self.date_indexs是否需要进行打乱\n",
    "        '''\n",
    "        if self.shuffle:\n",
    "            np.random.shuffle(self.date_indexs)\n",
    "    \n",
    "    def __getitem__(self,index):\n",
    "        # 预测的日期\n",
    "        pred_start = self.first_pred_start - timedelta(hours=self.date_indexs[index])\n",
    "        return create_dataset_base(self.df, self.dew_df, self.timesteps,self.periods, pred_start, is_train=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate RMSE scores for all 16 days, first 5 days (fror public LB) and 6th-16th days (for private LB) \n",
    "def cal_score(Ytrue, Yfit):\n",
    "    print([metrics.mean_squared_error(Ytrue, Yfit), \n",
    "           metrics.mean_squared_error(Ytrue[:,:5], Yfit[:,:5]),\n",
    "           metrics.mean_squared_error(Ytrue[:,5:], Yfit[:,5:])])    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "d1 = datetime.strptime('2014,12,11', '%Y,%m,%d')\n",
    "d2 = datetime.strptime('2010,01,02', '%Y,%m,%d')\n",
    "delta = d1 - d2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1804"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "delta.days"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_generator(df, dew_df, timesteps, first_pred_start,periods,\n",
    "    n_range, is_train=True):\n",
    "\n",
    "    while 1:\n",
    "        '''\n",
    "            打乱数据的时间顺序。\n",
    "            我的理解是假设1，2，3，4，5，6，7天的销量数据，如果按照顺序生成数据的,如下：\n",
    "            1 -> 2\n",
    "            1,2 -> 3\n",
    "            1,2,3 -> 4\n",
    "            1,2,3,4 -> 5\n",
    "            1,2,3,4,5 -> 6\n",
    "            1,2,3,4,5,6 -> 7\n",
    "            \n",
    "            打乱顺序后的数据如下，假设1，2，3，4，5，6，7天的列表打乱后为3，6，4，1，2，7，5\n",
    "            1,2 -> 3\n",
    "            1,2,3,4,5 -> 6\n",
    "            1,2,3 -> 4\n",
    "            1 -> 2\n",
    "            1,2,3,4,5,6 -> 7\n",
    "            1,2,3,4 -> 5\n",
    "            这样打乱顺序的数据，有一定的泛化能力\n",
    "        '''\n",
    "        date_part = np.random.permutation(range(n_range))\n",
    "        for i in date_part:\n",
    "            pred_start = first_pred_start - timedelta(hours=int(i))\n",
    "            yield create_dataset_base(df, dew_df, timesteps,periods, pred_start, is_train=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:start generate train val test data\n",
      "INFO:root:model begin init\n",
      "INFO:root:model begin train\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " - 55s - loss: nan\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:model train success\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:TensorFlow optimizers do not make it possible to access optimizer attributes or optimizer state after instantiation. As a result, we cannot save the optimizer as part of the model save file.You will have to compile your model again after loading it. Prefer using a Keras optimizer instead (see keras.io/optimizers).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:TensorFlow optimizers do not make it possible to access optimizer attributes or optimizer state after instantiation. As a result, we cannot save the optimizer as part of the model save file.You will have to compile your model again after loading it. Prefer using a Keras optimizer instead (see keras.io/optimizers).\n",
      "INFO:root:model save success\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Input contains NaN, infinity or a value too large for dtype('float32').",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-17-d2b1aaeadfbb>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m    117\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    118\u001b[0m \u001b[0mval_pred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mXval\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 119\u001b[0;31m \u001b[0mcal_score\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mYval\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval_pred\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-12-d38b67e989f4>\u001b[0m in \u001b[0;36mcal_score\u001b[0;34m(Ytrue, Yfit)\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# Calculate RMSE scores for all 16 days, first 5 days (fror public LB) and 6th-16th days (for private LB)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mcal_score\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mYtrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mYfit\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m     print([metrics.mean_squared_error(Ytrue, Yfit), \n\u001b[0m\u001b[1;32m      4\u001b[0m            \u001b[0mmetrics\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmean_squared_error\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mYtrue\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mYfit\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m            metrics.mean_squared_error(Ytrue[:,5:], Yfit[:,5:])])    \n",
      "\u001b[0;32m~/fengjiaxin/anaconda3/envs/my-rdkit-env/lib/python3.6/site-packages/sklearn/metrics/regression.py\u001b[0m in \u001b[0;36mmean_squared_error\u001b[0;34m(y_true, y_pred, sample_weight, multioutput)\u001b[0m\n\u001b[1;32m    239\u001b[0m     \"\"\"\n\u001b[1;32m    240\u001b[0m     y_type, y_true, y_pred, multioutput = _check_reg_targets(\n\u001b[0;32m--> 241\u001b[0;31m         y_true, y_pred, multioutput)\n\u001b[0m\u001b[1;32m    242\u001b[0m     \u001b[0mcheck_consistent_length\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_pred\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    243\u001b[0m     output_errors = np.average((y_true - y_pred) ** 2, axis=0,\n",
      "\u001b[0;32m~/fengjiaxin/anaconda3/envs/my-rdkit-env/lib/python3.6/site-packages/sklearn/metrics/regression.py\u001b[0m in \u001b[0;36m_check_reg_targets\u001b[0;34m(y_true, y_pred, multioutput)\u001b[0m\n\u001b[1;32m     77\u001b[0m     \u001b[0mcheck_consistent_length\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_pred\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     78\u001b[0m     \u001b[0my_true\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcheck_array\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mensure_2d\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 79\u001b[0;31m     \u001b[0my_pred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcheck_array\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_pred\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mensure_2d\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     80\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     81\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0my_true\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndim\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/fengjiaxin/anaconda3/envs/my-rdkit-env/lib/python3.6/site-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36mcheck_array\u001b[0;34m(array, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, ensure_min_samples, ensure_min_features, warn_on_dtype, estimator)\u001b[0m\n\u001b[1;32m    540\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mforce_all_finite\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    541\u001b[0m             _assert_all_finite(array,\n\u001b[0;32m--> 542\u001b[0;31m                                allow_nan=force_all_finite == 'allow-nan')\n\u001b[0m\u001b[1;32m    543\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    544\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mensure_min_samples\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/fengjiaxin/anaconda3/envs/my-rdkit-env/lib/python3.6/site-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36m_assert_all_finite\u001b[0;34m(X, allow_nan)\u001b[0m\n\u001b[1;32m     54\u001b[0m                 not allow_nan and not np.isfinite(X).all()):\n\u001b[1;32m     55\u001b[0m             \u001b[0mtype_err\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'infinity'\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mallow_nan\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;34m'NaN, infinity'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 56\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmsg_err\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtype_err\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     57\u001b[0m     \u001b[0;31m# for object dtype data, we only check for NaNs (GH-13254)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     58\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdtype\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'object'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mallow_nan\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Input contains NaN, infinity or a value too large for dtype('float32')."
     ]
    }
   ],
   "source": [
    "timesteps = 7 * 24\n",
    "periods = 1 * 24\n",
    "# 其中数据的最后一天日期是2014年12月31日\n",
    "\n",
    "logging.info('start generate train val test data')\n",
    "\n",
    "# 数据生成器\n",
    "# training_generator = DataGenerator(pollution_df, dew_df, timesteps, datetime(2014,12,11,0),200, periods,1,shuffle=True)\n",
    "train_data = train_generator(pollution_df, dew_df, timesteps, datetime(2014,12,11,0),periods,200)\n",
    "\n",
    "\n",
    "Xval, Yval = create_dataset(pollution_df, dew_df, timesteps, periods,datetime(2014,12,18,0), is_train=True)\n",
    "\n",
    "Xtest, Ytest = create_dataset(pollution_df, dew_df, timesteps, periods,datetime(2014,12,25,0), is_train=True)\n",
    "\n",
    "# del df, dew_df; gc.collect()\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "latent_dim = 3\n",
    "# input [X,dew,hour,weekday,dayOfMonth]\n",
    "\n",
    "seq_in = Input(shape=(timesteps, 1))\n",
    "\n",
    "# 下面这些特征都是已知的\n",
    "dew_in = Input(shape=(timesteps+periods, 1))\n",
    "hour_in = Input(shape=(timesteps+periods, 1))\n",
    "\n",
    "weekday_in = Input(shape=(timesteps+periods, 1))\n",
    "dayOfMonth_in = Input(shape=(timesteps+periods, 1))\n",
    "\n",
    "#weekday_in = Input(shape=(timesteps+periods,), dtype='uint8')\n",
    "#weekday_embed_encode = Embedding(7, 4, input_length=timesteps+periods)(weekday_in)\n",
    "\n",
    "#dayOfMonth_in = Input(shape=(timesteps+periods,), dtype='uint8')\n",
    "#dayOfMonth_embed_encode = Embedding(31, 7, input_length=timesteps+periods)(dayOfMonth_in)\n",
    "\n",
    "\n",
    "\n",
    "# Encoder\n",
    "# 截取前timesteps时间步的数据\n",
    "encode_slice = Lambda(lambda x: x[:, :timesteps, :])\n",
    "# 合并已知的特征向量\n",
    "#encode_features = concatenate([dew_in, hour_in, weekday_embed_encode, dayOfMonth_embed_encode], axis=2)\n",
    "\n",
    "encode_features = concatenate([dew_in, hour_in, weekday_in, dayOfMonth_in], axis=2)\n",
    "\n",
    "encode_features = encode_slice(encode_features)\n",
    "\n",
    "conv_in =Conv1D(4, 5, padding='same')(seq_in)\n",
    "\n",
    "\n",
    "x_encode = concatenate([seq_in, encode_features, conv_in], axis=2)\n",
    "\n",
    "encoder = GRU(latent_dim, return_state=True)\n",
    "#logging.info('Input dimension:', x_encode.shape)\n",
    "\n",
    "_, h= encoder(x_encode)\n",
    "\n",
    "\n",
    "# Connector\n",
    "h = Dense(latent_dim, activation='tanh')(h)\n",
    "\n",
    "\n",
    "# Decoder\n",
    "previous_x = Lambda(lambda x: x[:, -1, :])(seq_in)\n",
    "\n",
    "decode_slice = Lambda(lambda x: x[:, timesteps:, :])\n",
    "\n",
    "#decode_features = concatenate([dew_in, hour_in, weekday_embed_encode, dayOfMonth_embed_encode], axis=2)\n",
    "decode_features = concatenate([dew_in, hour_in, weekday_in, dayOfMonth_in], axis=2)\n",
    "\n",
    "decode_features = decode_slice(decode_features)\n",
    "\n",
    "\n",
    "decoder = GRU(latent_dim, return_state=True, return_sequences=False)\n",
    "decoder_dense = Dense(1, activation='relu')\n",
    "\n",
    "# 需求 x:[batch_size,timesteps,feature_size] 想获取第i个时间步的特征  t时刻的特征[batch_size,1,feature_size]\n",
    "slice_at_t = Lambda(lambda x: tf.slice(x, [0,i,0], [-1,1,-1]))\n",
    "\n",
    "for i in range(periods):\n",
    "    \n",
    "    previous_x = Reshape((1,1))(previous_x)\n",
    "    \n",
    "    features_t = slice_at_t(decode_features)\n",
    "\n",
    "    decode_input = concatenate([previous_x, features_t], axis=2)\n",
    "\n",
    "    output_x, h = decoder(decode_input, initial_state=h)\n",
    "\n",
    "    output_x = decoder_dense(output_x)\n",
    "\n",
    "    # gather outputs\n",
    "    if i == 0: decoder_outputs = output_x\n",
    "    elif i > 0: decoder_outputs = concatenate([decoder_outputs, output_x])\n",
    "\n",
    "    previous_x = output_x\n",
    "\n",
    "\n",
    "logging.info('model begin init')\n",
    "\n",
    "# [X,dew,hour,weekday,dayOfMonth],y\n",
    "model = Model([seq_in, dew_in, hour_in, weekday_in,dayOfMonth_in], decoder_outputs)\n",
    "\n",
    "logging.info('model begin train')\n",
    "model.compile(optimizer=tf.train.RMSPropOptimizer(0.01), loss=tf.keras.losses.categorical_crossentropy)\n",
    "#history = model.fit_generator(training_generator, workers=3,use_multiprocessing=True, epochs=18, verbose=2,validation_data=(Xval, Yval))\n",
    "history = model.fit_generator(train_data,steps_per_epoch = 200, workers=1,use_multiprocessing=False, epochs=1, verbose=2)\n",
    "logging.info('model train success')\n",
    "\n",
    "model.save('../model/seq2seq_baseline_model.h5')\n",
    "\n",
    "logging.info('model save success')\n",
    "\n",
    "val_pred = model.predict(Xval)\n",
    "cal_score(Yval, val_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "datetime(2014,12,11,0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pollution_df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pollution_df[pd.date_range(datetime(2014,12,11,0), periods=11,freq='D')].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "datetime(2014,12,18,0) - timedelta(hours=30 * 24)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.date_range(datetime(2014,12,18,0) - timedelta(hours=30 * 24), periods=(30 * 24)+(7 * 24),freq='H')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "30 * 24"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Yval.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Xval[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Xval, Yval = create_dataset(pollution_df, dew_df, timesteps, periods,datetime(2014,12,18,0), is_train=True)\n",
    "\n",
    "y = pollution_df[pd.date_range(datetime(2014,12,18,0), 7 * 24,freq='H')].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.date_range(datetime(2014,12,18,0), periods = 7*24,freq='H')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.date_range(datetime(2014,12,18,0)-timedelta(hours=30 * 24), datetime(2014,12,18,0)-timedelta(hours=1),freq='H')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "date_indexs = range(11)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_start = datetime(2014,12,18,0) - timedelta(hours=date_indexs[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_start"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(training_generator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "seq_in = Input(shape=(timesteps, 1))\n",
    "\n",
    "# 下面这些特征都是已知的\n",
    "dew_in = Input(shape=(timesteps+periods, 1))\n",
    "hour_in = Input(shape=(timesteps+periods, 1))\n",
    "\n",
    "weekday_in = Input(shape=(timesteps+periods,), dtype='uint8')\n",
    "weekday_embed_encode = Embedding(7, 4, input_length=timesteps+periods)(weekday_in)\n",
    "\n",
    "dayOfMonth_in = Input(shape=(timesteps+periods,), dtype='uint8')\n",
    "dayOfMonth_embed_encode = Embedding(31, 7, input_length=timesteps+periods)(dayOfMonth_in)\n",
    "\n",
    "\n",
    "\n",
    "# Encoder\n",
    "# 截取前timesteps时间步的数据\n",
    "encode_slice = Lambda(lambda x: x[:, :timesteps, :])\n",
    "# 合并已知的特征向量\n",
    "encode_features = concatenate([dew_in, hour_in, weekday_embed_encode, dayOfMonth_embed_encode], axis=2)\n",
    "encode_features = encode_slice(encode_features)\n",
    "\n",
    "conv_in =Conv1D(4, 5, padding='same')(seq_in)\n",
    "\n",
    "\n",
    "x_encode = concatenate([seq_in, encode_features, conv_in], axis=2)\n",
    "\n",
    "logging.info('Input dimension:' + str(x_encode.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(features_t.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features_t = slice_at_t(decode_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_generator.next()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
