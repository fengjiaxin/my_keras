{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### baseline"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "最简单的seq2seq_baseline\n",
    "其中预测当天小时的污染程度，但是有一些自变量是已知的\n",
    "并且前几天的污染程度也可以当作一些特征，问题的关键是如何构建这些特征进行训练\n",
    "应用keras ,而不是使用tensorflow 的keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "def warn(*args, **kwargs):\n",
    "    pass\n",
    "import warnings\n",
    "warnings.warn = warn\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from datetime import date, timedelta,datetime\n",
    "import gc\n",
    "from sklearn import metrics\n",
    "from tensorflow.keras import Model\n",
    "from tensorflow.keras.layers import Input,Lambda,concatenate,GRU,Dense,Conv1D,Reshape,Embedding\n",
    "from tensorflow.keras.utils import Sequence\n",
    "import math\n",
    "import logging\n",
    "logging.basicConfig(level=logging.INFO)\n",
    "import os\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '3'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_df = pd.read_csv('../data/pollution.csv',parse_dates = ['date'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>pollution</th>\n",
       "      <th>dew</th>\n",
       "      <th>temp</th>\n",
       "      <th>press</th>\n",
       "      <th>wnd_dir</th>\n",
       "      <th>wnd_spd</th>\n",
       "      <th>snow</th>\n",
       "      <th>rain</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2010-01-02 00:00:00</td>\n",
       "      <td>129.0</td>\n",
       "      <td>-16</td>\n",
       "      <td>-4.0</td>\n",
       "      <td>1020.0</td>\n",
       "      <td>SE</td>\n",
       "      <td>1.79</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2010-01-02 01:00:00</td>\n",
       "      <td>148.0</td>\n",
       "      <td>-15</td>\n",
       "      <td>-4.0</td>\n",
       "      <td>1020.0</td>\n",
       "      <td>SE</td>\n",
       "      <td>2.68</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2010-01-02 02:00:00</td>\n",
       "      <td>159.0</td>\n",
       "      <td>-11</td>\n",
       "      <td>-5.0</td>\n",
       "      <td>1021.0</td>\n",
       "      <td>SE</td>\n",
       "      <td>3.57</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2010-01-02 03:00:00</td>\n",
       "      <td>181.0</td>\n",
       "      <td>-7</td>\n",
       "      <td>-5.0</td>\n",
       "      <td>1022.0</td>\n",
       "      <td>SE</td>\n",
       "      <td>5.36</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2010-01-02 04:00:00</td>\n",
       "      <td>138.0</td>\n",
       "      <td>-7</td>\n",
       "      <td>-5.0</td>\n",
       "      <td>1022.0</td>\n",
       "      <td>SE</td>\n",
       "      <td>6.25</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 date  pollution  dew  temp   press wnd_dir  wnd_spd  snow  \\\n",
       "0 2010-01-02 00:00:00      129.0  -16  -4.0  1020.0      SE     1.79     0   \n",
       "1 2010-01-02 01:00:00      148.0  -15  -4.0  1020.0      SE     2.68     0   \n",
       "2 2010-01-02 02:00:00      159.0  -11  -5.0  1021.0      SE     3.57     0   \n",
       "3 2010-01-02 03:00:00      181.0   -7  -5.0  1022.0      SE     5.36     1   \n",
       "4 2010-01-02 04:00:00      138.0   -7  -5.0  1022.0      SE     6.25     2   \n",
       "\n",
       "   rain  \n",
       "0     0  \n",
       "1     0  \n",
       "2     0  \n",
       "3     0  \n",
       "4     0  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "raw_df.head()"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "可以看出数据的日期是 从 2010-01-02 00:00:00  到  2014-12-31 23:00:00\n",
    "其中说明一下各列代表的含义：\n",
    "pollution:PM2.5浓度\n",
    "dew:露点\n",
    "temp:温度\n",
    "press:压力\n",
    "wnd_dir:综合风向\n",
    "wnd_spd:累计风速\n",
    "snow:累计下了几个小时的雪\n",
    "rain:累计下了几个小时的雨"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "目的：生成两个df\n",
    "pollution_df:只有一行，多列，其中列是日期，value是污染pollution\n",
    "dew_df:只有一行，多列，其中列是日期，value是露点dew"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 生成pollution_df\n",
    "raw_df['variable'] = 'pollution'\n",
    "pollution_df = raw_df[['date','pollution','variable']].set_index(['variable','date'])[['pollution']].unstack(level=-1)\n",
    "pollution_df.columns = pollution_df.columns.get_level_values(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>date</th>\n",
       "      <th>2010-01-02 00:00:00</th>\n",
       "      <th>2010-01-02 01:00:00</th>\n",
       "      <th>2010-01-02 02:00:00</th>\n",
       "      <th>2010-01-02 03:00:00</th>\n",
       "      <th>2010-01-02 04:00:00</th>\n",
       "      <th>2010-01-02 05:00:00</th>\n",
       "      <th>2010-01-02 06:00:00</th>\n",
       "      <th>2010-01-02 07:00:00</th>\n",
       "      <th>2010-01-02 08:00:00</th>\n",
       "      <th>2010-01-02 09:00:00</th>\n",
       "      <th>...</th>\n",
       "      <th>2014-12-31 14:00:00</th>\n",
       "      <th>2014-12-31 15:00:00</th>\n",
       "      <th>2014-12-31 16:00:00</th>\n",
       "      <th>2014-12-31 17:00:00</th>\n",
       "      <th>2014-12-31 18:00:00</th>\n",
       "      <th>2014-12-31 19:00:00</th>\n",
       "      <th>2014-12-31 20:00:00</th>\n",
       "      <th>2014-12-31 21:00:00</th>\n",
       "      <th>2014-12-31 22:00:00</th>\n",
       "      <th>2014-12-31 23:00:00</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>variable</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>pollution</th>\n",
       "      <td>129.0</td>\n",
       "      <td>148.0</td>\n",
       "      <td>159.0</td>\n",
       "      <td>181.0</td>\n",
       "      <td>138.0</td>\n",
       "      <td>109.0</td>\n",
       "      <td>105.0</td>\n",
       "      <td>124.0</td>\n",
       "      <td>120.0</td>\n",
       "      <td>132.0</td>\n",
       "      <td>...</td>\n",
       "      <td>9.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>12.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1 rows × 43800 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "date       2010-01-02 00:00:00  2010-01-02 01:00:00  2010-01-02 02:00:00  \\\n",
       "variable                                                                   \n",
       "pollution                129.0                148.0                159.0   \n",
       "\n",
       "date       2010-01-02 03:00:00  2010-01-02 04:00:00  2010-01-02 05:00:00  \\\n",
       "variable                                                                   \n",
       "pollution                181.0                138.0                109.0   \n",
       "\n",
       "date       2010-01-02 06:00:00  2010-01-02 07:00:00  2010-01-02 08:00:00  \\\n",
       "variable                                                                   \n",
       "pollution                105.0                124.0                120.0   \n",
       "\n",
       "date       2010-01-02 09:00:00  ...  2014-12-31 14:00:00  2014-12-31 15:00:00  \\\n",
       "variable                        ...                                             \n",
       "pollution                132.0  ...                  9.0                 11.0   \n",
       "\n",
       "date       2014-12-31 16:00:00  2014-12-31 17:00:00  2014-12-31 18:00:00  \\\n",
       "variable                                                                   \n",
       "pollution                  8.0                  9.0                 10.0   \n",
       "\n",
       "date       2014-12-31 19:00:00  2014-12-31 20:00:00  2014-12-31 21:00:00  \\\n",
       "variable                                                                   \n",
       "pollution                  8.0                 10.0                 10.0   \n",
       "\n",
       "date       2014-12-31 22:00:00  2014-12-31 23:00:00  \n",
       "variable                                             \n",
       "pollution                  8.0                 12.0  \n",
       "\n",
       "[1 rows x 43800 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pollution_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 生成dew_df\n",
    "raw_df['variable'] = 'dew'\n",
    "dew_df = raw_df[['date','pollution','variable']].set_index(['variable','date'])[['pollution']].unstack(level=-1)\n",
    "dew_df.columns = dew_df.columns.get_level_values(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>date</th>\n",
       "      <th>2010-01-02 00:00:00</th>\n",
       "      <th>2010-01-02 01:00:00</th>\n",
       "      <th>2010-01-02 02:00:00</th>\n",
       "      <th>2010-01-02 03:00:00</th>\n",
       "      <th>2010-01-02 04:00:00</th>\n",
       "      <th>2010-01-02 05:00:00</th>\n",
       "      <th>2010-01-02 06:00:00</th>\n",
       "      <th>2010-01-02 07:00:00</th>\n",
       "      <th>2010-01-02 08:00:00</th>\n",
       "      <th>2010-01-02 09:00:00</th>\n",
       "      <th>...</th>\n",
       "      <th>2014-12-31 14:00:00</th>\n",
       "      <th>2014-12-31 15:00:00</th>\n",
       "      <th>2014-12-31 16:00:00</th>\n",
       "      <th>2014-12-31 17:00:00</th>\n",
       "      <th>2014-12-31 18:00:00</th>\n",
       "      <th>2014-12-31 19:00:00</th>\n",
       "      <th>2014-12-31 20:00:00</th>\n",
       "      <th>2014-12-31 21:00:00</th>\n",
       "      <th>2014-12-31 22:00:00</th>\n",
       "      <th>2014-12-31 23:00:00</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>variable</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>dew</th>\n",
       "      <td>129.0</td>\n",
       "      <td>148.0</td>\n",
       "      <td>159.0</td>\n",
       "      <td>181.0</td>\n",
       "      <td>138.0</td>\n",
       "      <td>109.0</td>\n",
       "      <td>105.0</td>\n",
       "      <td>124.0</td>\n",
       "      <td>120.0</td>\n",
       "      <td>132.0</td>\n",
       "      <td>...</td>\n",
       "      <td>9.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>12.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1 rows × 43800 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "date      2010-01-02 00:00:00  2010-01-02 01:00:00  2010-01-02 02:00:00  \\\n",
       "variable                                                                  \n",
       "dew                     129.0                148.0                159.0   \n",
       "\n",
       "date      2010-01-02 03:00:00  2010-01-02 04:00:00  2010-01-02 05:00:00  \\\n",
       "variable                                                                  \n",
       "dew                     181.0                138.0                109.0   \n",
       "\n",
       "date      2010-01-02 06:00:00  2010-01-02 07:00:00  2010-01-02 08:00:00  \\\n",
       "variable                                                                  \n",
       "dew                     105.0                124.0                120.0   \n",
       "\n",
       "date      2010-01-02 09:00:00  ...  2014-12-31 14:00:00  2014-12-31 15:00:00  \\\n",
       "variable                       ...                                             \n",
       "dew                     132.0  ...                  9.0                 11.0   \n",
       "\n",
       "date      2014-12-31 16:00:00  2014-12-31 17:00:00  2014-12-31 18:00:00  \\\n",
       "variable                                                                  \n",
       "dew                       8.0                  9.0                 10.0   \n",
       "\n",
       "date      2014-12-31 19:00:00  2014-12-31 20:00:00  2014-12-31 21:00:00  \\\n",
       "variable                                                                  \n",
       "dew                       8.0                 10.0                 10.0   \n",
       "\n",
       "date      2014-12-31 22:00:00  2014-12-31 23:00:00  \n",
       "variable                                            \n",
       "dew                       8.0                 12.0  \n",
       "\n",
       "[1 rows x 43800 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dew_df"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "整理思路：\n",
    "1.首先需要预测的是pollution\n",
    "2.需要预测的是后7天的每个小时的污染程度\n",
    "3.先假定根据前一个月的数据来预测后7天的数据\n",
    "\n",
    "\n",
    "有个理解错误的地方\n",
    "timesetps时间步的含义是t时刻的value 与 t-timesteps ~ t-1 的value相关\n",
    "在decoder的过程中，需要不断更新seq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_xy_span(df, pred_start, timesteps,periods,is_train=True):\n",
    "    '''\n",
    "        function:首先说一下需求，然后才能更好的了解函数的功能\n",
    "        需求:该时刻的pollution可能和60天前的pollution相关，需要将60天前的pollution提取出来，作为该时刻的特征\n",
    "        timesteps代笔时间步，我们需要构建timesteps个时刻的的特征\n",
    "        periods代表需要预测的时间段长度        \n",
    "    '''\n",
    "    X = df[pd.date_range(pred_start-timedelta(hours=timesteps), pred_start-timedelta(hours=1),freq='H')].values\n",
    "    if is_train: y = df[pd.date_range(pred_start, periods = periods,freq='H')].values\n",
    "    else: y = None\n",
    "    return X, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_dataset_base(df, dew_df, timesteps,periods, pred_start, is_train):\n",
    "    '''\n",
    "        function:创建数据集合\n",
    "        df:污染数据\n",
    "        dew_df:露点数据\n",
    "        timesteps:时间步\n",
    "        pred_start:开始预测的时间点\n",
    "        periods:后续预测的时间段\n",
    "        is_train:是否是训练数据\n",
    "    '''\n",
    "\n",
    "    # 首先可以获取最基本的pollution数据\n",
    "    # X:[1,timesteps] y:[1,periods]\n",
    "    X, y = create_xy_span(df, pred_start, timesteps,periods,is_train)\n",
    "    \n",
    "    # dew 包含训练和测试的露点数据\n",
    "    # dew:[1,timesteps + periods]\n",
    "    dew = dew_df[pd.date_range(pred_start-timedelta(hours=timesteps), periods=timesteps+periods,freq='H')].values\n",
    "    \n",
    "    \n",
    "    # 获取hour特征 hour:[1,timesteps + periods]\n",
    "    hour = np.tile([d.hour for d in pd.date_range(pred_start-timedelta(hours=timesteps), periods=timesteps+periods,freq='H')],\n",
    "                          (X.shape[0],1))\n",
    "    \n",
    "    # 获取week特征 week:[1,timesteps + periods]\n",
    "    weekday = np.tile([d.weekday() for d in pd.date_range(pred_start-timedelta(hours=timesteps), periods=timesteps+periods,freq='H')],\n",
    "                          (X.shape[0],1))\n",
    "    # 获取day特征 day:[1,timesteps + periods]\n",
    "    dayOfMonth = np.tile([d.day-1 for d in pd.date_range(pred_start-timedelta(hours=timesteps), periods=timesteps+periods,freq='H')],\n",
    "                          (X.shape[0],1))\n",
    "    \n",
    "    # 将3个月前,91天的pollution作为特征 quater:[1,timesteps + periods]\n",
    "    #qauaterAgo, _ = create_xy_span(df, pred_start-timedelta(days=91), timesteps+16, False)\n",
    "    \n",
    "    # reshape 数据\n",
    "    X= X.reshape(-1,timesteps,1)\n",
    "    dew = dew.reshape(-1, timesteps + periods, 1)\n",
    "    #hour = hour.reshape(-1, timesteps + periods, 1)\n",
    "    #weekday = weekday.reshape(-1, timesteps + periods, 1)\n",
    "    #dayOfMonth = dayOfMonth.reshape(-1, timesteps + periods, 1)\n",
    "    #qauaterAgo = qauaterAgo.reshape(-1, timesteps + periods, 1)\n",
    "\n",
    "    #return ([X,dew,weekAgo,hour,weekday,dayOfMonth,qauaterAgo],y)\n",
    "    return ([X,dew,hour,weekday,dayOfMonth],y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create validation and test data\n",
    "def create_dataset(df, dew_df, timesteps, periods,first_pred_start, is_train=True):\n",
    "    return create_dataset_base(df, dew_df, timesteps,periods, first_pred_start, is_train)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "接下来创建训练数据生成器，每次批量生成数据\n",
    "在这个例子中，batch_size = 1\n",
    "n_range 代表生成多少个样本"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DataGenerator(Sequence):\n",
    "    '''\n",
    "        generate data for keras\n",
    "        df,dew_df都是一行数据\n",
    "        这个比较特殊，只能先设定batch_size = 1\n",
    "    '''\n",
    "    def __init__(self,pollution_df, dew_df, timesteps, first_pred_start,n_range, periods, batch_size,shuffle=True):\n",
    "        '''\n",
    "            df:pollution数据，列为时间\n",
    "            dew_df:露点数据，列为时间\n",
    "            timesteps:时间步\n",
    "            first_pred_start:需要预测pollution的开始日期\n",
    "            n_range:代表可以划分为多少个时间段数据\n",
    "            假设df 列 如下：\n",
    "            1.1,1.2,1.3,1.4,1.5,1.6,1.7,1.8,1.9,1.10\n",
    "            timesteps = 3\n",
    "            periods = 2\n",
    "            first_pred_start = 1.9\n",
    "            那么可以确定划分为6份数据\n",
    "            batch_size:批量数据\n",
    "        '''\n",
    "        self.pollution_df = pollution_df\n",
    "        self.dew_df = dew_df\n",
    "        self.timesteps = timesteps\n",
    "        self.first_pred_start = first_pred_start\n",
    "        self.n_range = n_range\n",
    "        self.periods = periods\n",
    "        if batch_size != 1:\n",
    "            self.batch_size = 1\n",
    "        else:\n",
    "            self.batch_size = batch_size\n",
    "        self.shuffle = shuffle\n",
    "        self.on_epoch_end()\n",
    "        \n",
    "        \n",
    "    def __len__(self):\n",
    "        '''\n",
    "            计算每一个epoch的迭代个数\n",
    "        '''\n",
    "        return math.ceil(self.n_range/self.batch_size)\n",
    "    \n",
    "    \n",
    "    def on_epoch_end(self):\n",
    "        '''\n",
    "            每次epoch结束后,self.date_indexs是否需要进行打乱\n",
    "        '''\n",
    "        self.date_indexs = np.arange(self.n_range)\n",
    "        if self.shuffle:\n",
    "            np.random.shuffle(self.date_indexs)\n",
    "    \n",
    "    def __getitem__(self,index):\n",
    "        # 预测的日期\n",
    "        pred_start = self.first_pred_start - timedelta(hours=int(self.date_indexs[index]))\n",
    "        return create_dataset_base(self.pollution_df, self.dew_df, self.timesteps,self.periods, pred_start, is_train=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate RMSE scores for all 16 days, first 5 days (fror public LB) and 6th-16th days (for private LB) \n",
    "def cal_score(Ytrue, Yfit):\n",
    "    print([metrics.mean_squared_error(Ytrue, Yfit), \n",
    "           metrics.mean_squared_error(Ytrue[:,:5], Yfit[:,:5]),\n",
    "           metrics.mean_squared_error(Ytrue[:,5:], Yfit[:,5:])])    "
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "d1 = datetime.strptime('2014,12,11', '%Y,%m,%d')\n",
    "d2 = datetime.strptime('2010,01,02', '%Y,%m,%d')\n",
    "delta = d1 - d2\n",
    "delta.days"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:start generate train val test data\n",
      "INFO:root:end generate train val test data\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/fengjiaxin/fengjiaxin/anaconda3/envs/my-rdkit-env/lib/python3.6/site-packages/tensorflow/python/ops/resource_variable_ops.py:435: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/fengjiaxin/fengjiaxin/anaconda3/envs/my-rdkit-env/lib/python3.6/site-packages/tensorflow/python/ops/resource_variable_ops.py:435: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n",
      "INFO:root:model begin define\n",
      "INFO:root:model begin compile\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/fengjiaxin/fengjiaxin/anaconda3/envs/my-rdkit-env/lib/python3.6/site-packages/tensorflow/python/keras/utils/losses_utils.py:170: to_float (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/fengjiaxin/fengjiaxin/anaconda3/envs/my-rdkit-env/lib/python3.6/site-packages/tensorflow/python/keras/utils/losses_utils.py:170: to_float (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n",
      "INFO:root:model begin train\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/fengjiaxin/fengjiaxin/anaconda3/envs/my-rdkit-env/lib/python3.6/site-packages/tensorflow/python/ops/math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/fengjiaxin/fengjiaxin/anaconda3/envs/my-rdkit-env/lib/python3.6/site-packages/tensorflow/python/ops/math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3\n",
      " 99/100 [============================>.] - ETA: 0s - loss: 27010.1885WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 3s 3s/sample - loss: 30415.8730\n",
      "100/100 [==============================] - 45s 447ms/step - loss: 26751.7307 - val_loss: 30415.8730\n",
      "Epoch 2/3\n",
      " 99/100 [============================>.] - ETA: 0s - loss: 25970.8688WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 110ms/sample - loss: 30412.8125\n",
      "100/100 [==============================] - 15s 149ms/step - loss: 26749.0426 - val_loss: 30412.8125\n",
      "Epoch 3/3\n",
      " 99/100 [============================>.] - ETA: 0s - loss: 27009.7022WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 105ms/sample - loss: 30409.4688\n",
      "100/100 [==============================] - 15s 152ms/step - loss: 26747.2788 - val_loss: 30409.4688\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:model train success\n",
      "INFO:root:model save success\n"
     ]
    }
   ],
   "source": [
    "timesteps = 7 * 24\n",
    "periods = 1 * 24\n",
    "# 其中数据的最后一天日期是2014年12月31日\n",
    "\n",
    "logging.info('start generate train val test data')\n",
    "\n",
    "# 数据生成器\n",
    "training_generator = DataGenerator(pollution_df, dew_df, timesteps, datetime(2014,12,11,0),100, periods,1,shuffle=True)\n",
    "#train_data = train_generator(pollution_df, dew_df, timesteps, datetime(2014,12,11,0),periods,200)\n",
    "\n",
    "\n",
    "Xval, Yval = create_dataset(pollution_df, dew_df, timesteps, periods,datetime(2014,12,18,0), is_train=True)\n",
    "logging.info('end generate train val test data')\n",
    "\n",
    "Xtest, Ytest = create_dataset(pollution_df, dew_df, timesteps, periods,datetime(2014,12,25,0), is_train=True)\n",
    "\n",
    "# del df, dew_df; gc.collect()\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "latent_dim = 3\n",
    "# input [X,dew,hour,weekday,dayOfMonth]\n",
    "\n",
    "seq_in = Input(shape=(timesteps, 1))\n",
    "\n",
    "# 下面这些特征都是已知的\n",
    "dew_in = Input(shape=(timesteps+periods, 1))\n",
    "\n",
    "# embedding\n",
    "hour_in = Input(shape=(timesteps+periods,),dtype='uint8')\n",
    "hour_embed_encode = Embedding(24, 6, input_length=timesteps+periods)(hour_in)\n",
    "\n",
    "\n",
    "weekday_in = Input(shape=(timesteps+periods,), dtype='uint8')\n",
    "weekday_embed_encode = Embedding(7, 4, input_length=timesteps+periods)(weekday_in)\n",
    "\n",
    "dayOfMonth_in = Input(shape=(timesteps+periods,), dtype='uint8')\n",
    "dayOfMonth_embed_encode = Embedding(31, 7, input_length=timesteps+periods)(dayOfMonth_in)\n",
    "\n",
    "\n",
    "\n",
    "# Encoder\n",
    "# 截取前timesteps时间步的数据\n",
    "encode_slice = Lambda(lambda x: x[:, :timesteps, :])\n",
    "# 合并已知的特征向量\n",
    "encode_features = concatenate([dew_in, hour_embed_encode, weekday_embed_encode, dayOfMonth_embed_encode], axis=2)\n",
    "\n",
    "encode_features = encode_slice(encode_features)\n",
    "\n",
    "conv_in =Conv1D(4, 5, padding='same')(seq_in)\n",
    "\n",
    "x_encode = concatenate([seq_in, encode_features, conv_in], axis=2)\n",
    "\n",
    "encoder = GRU(latent_dim, return_state=True)\n",
    "\n",
    "_, h= encoder(x_encode)\n",
    "\n",
    "\n",
    "# Connector\n",
    "h = Dense(latent_dim, activation='tanh')(h)\n",
    "\n",
    "\n",
    "# Decoder\n",
    "previous_x = Lambda(lambda x: x[:, -1, :])(seq_in)\n",
    "\n",
    "decode_slice = Lambda(lambda x: x[:, timesteps:, :])\n",
    "\n",
    "decode_features = concatenate([dew_in, hour_embed_encode, weekday_embed_encode, dayOfMonth_embed_encode], axis=2)\n",
    "\n",
    "decode_features = decode_slice(decode_features)\n",
    "\n",
    "\n",
    "decoder = GRU(latent_dim, return_state=True, return_sequences=False)\n",
    "decoder_dense = Dense(1, activation='relu')\n",
    "\n",
    "# 需求 x:[batch_size,timesteps,feature_size] 想获取第i个时间步的特征  t时刻的特征[batch_size,1,feature_size]\n",
    "slice_at_t = Lambda(lambda x: x[:,i:i+1,:])\n",
    "\n",
    "for i in range(periods):\n",
    "    \n",
    "    previous_x = Reshape((1,1))(previous_x)\n",
    "    \n",
    "    features_t = slice_at_t(decode_features)\n",
    "\n",
    "    decode_input = concatenate([previous_x, features_t], axis=2)\n",
    "\n",
    "    output_x, h = decoder(decode_input, initial_state=h)\n",
    "\n",
    "    output_x = decoder_dense(output_x)\n",
    "\n",
    "    # gather outputs\n",
    "    if i == 0: decoder_outputs = output_x\n",
    "    elif i > 0: decoder_outputs = concatenate([decoder_outputs, output_x])\n",
    "\n",
    "    previous_x = output_x\n",
    "\n",
    "\n",
    "logging.info('model begin define')\n",
    "\n",
    "# [X,dew,hour,weekday,dayOfMonth],y\n",
    "model = Model([seq_in, dew_in, hour_in, weekday_in,dayOfMonth_in], decoder_outputs)\n",
    "\n",
    "logging.info('model begin compile')\n",
    "\n",
    "model.compile(optimizer='adam', loss='mean_squared_error')\n",
    "\n",
    "logging.info('model begin train')\n",
    "\n",
    "history = model.fit_generator(training_generator, workers=2,use_multiprocessing=True, epochs=3, verbose=1,validation_data=(Xval, Yval))\n",
    "logging.info('model train success')\n",
    "\n",
    "model.save('../model/seq2seq_baseline_model.h5')\n",
    "\n",
    "logging.info('model save success')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[30409.46923510289, 24639.252328493858, 31927.947368421053]\n"
     ]
    }
   ],
   "source": [
    "val_pred = model.predict(Xval)\n",
    "cal_score(Yval, val_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TensorShape([Dimension(None), Dimension(1)])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "previous_x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "__call__() missing 1 required positional argument: 'inputs'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-16-478e26863523>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mslice_at_t\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m: __call__() missing 1 required positional argument: 'inputs'"
     ]
    }
   ],
   "source": [
    "slice_at_t()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tt = Lambda(lambda x: x[:,2:3,:])(decode_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "decode_features.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tt.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "math.ceil(100/3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "date_indexs = np.arange(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "date_indexs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.shuffle(date_indexs)\n",
    "date_indexs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "type(date_indexs[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "datetime(2014,12,18,0) - timedelta(hours=int(date_indexs[3]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
